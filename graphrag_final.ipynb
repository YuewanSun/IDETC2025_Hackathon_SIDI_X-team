{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95712eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pt8527\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from neo4j import GraphDatabase\n",
    "from dotenv import load_dotenv\n",
    "import ast\n",
    "import os\n",
    "from neo4j_graphrag.generation import GraphRAG\n",
    "from neo4j_graphrag.retrievers import VectorCypherRetriever\n",
    "from neo4j_graphrag.types import RetrieverResultItem\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4b5b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "URI = os.getenv(\"NEO4J_URI\")\n",
    "USER = os.getenv(\"NEO4J_USER\")\n",
    "PASSWORD = os.getenv(\"NEO4J_PASSWORD\")\n",
    "\n",
    "my_token = os.getenv(\"HF_TOKEN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1529685",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chunk_id</th>\n",
       "      <th>text</th>\n",
       "      <th>rule_numbers</th>\n",
       "      <th>keywords</th>\n",
       "      <th>cluster_group_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>GR - GENERAL REGULATIONS GR.1 FORMULA SAE COMP...</td>\n",
       "      <td>[\"EV.5.2\", \"GR.1.2.3\", \"GR.1.3\", \"GR.1.4\", \"GR...</td>\n",
       "      <td>[\"Build\", \"Competition\", \"Demonstration\", \"Des...</td>\n",
       "      <td>[\"Cluster 447\", \"Cluster 214\", \"Cluster 12\", \"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>GR.1.4.2 The vehicle should have high performa...</td>\n",
       "      <td>[\"GR.1.4.2\", \"GR.1.4.3\", \"GR.1.4.4\", \"GR.1.5\",...</td>\n",
       "      <td>[\"Dynamic events\", \"Static events\", \"aesthetic...</td>\n",
       "      <td>[\"Cluster 56\", \"Cluster 63\", \"Cluster 219\", \"C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>GR.2.4 Restriction on Vehicle Use SAE Internat...</td>\n",
       "      <td>[\"GR.1.2.3\", \"GR.3.1\", \"GR.3.2\", \"GR.3.3\", \"GR...</td>\n",
       "      <td>[\"Competition organizers\", \"Competition site\",...</td>\n",
       "      <td>[\"Cluster 105\", \"Cluster 214\", \"Cluster 87\", \"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>GR.3.5.2 If a team is not present and ready to...</td>\n",
       "      <td>[\"GR.3.5.2\", \"GR.3.5.3\", \"GR.4.1\", \"GR.4.2.1\",...</td>\n",
       "      <td>[\"Competition\", \"Competition year\", \"Draft rul...</td>\n",
       "      <td>[\"Cluster 214\", \"Cluster 65\", \"Cluster 87\", \"C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>GR.4.4 Rules Compliance GR.4.4.1 All participa...</td>\n",
       "      <td>[\"GR.4.4\", \"GR.4.4.1\", \"GR.4.4.2\", \"GR.4.4.3\",...</td>\n",
       "      <td>[\"FSAE Online Website\", \"Formula SAE Rules\", \"...</td>\n",
       "      <td>[\"Cluster 231\", \"Cluster 87\", \"Cluster 48\", \"C...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   chunk_id                                               text  \\\n",
       "0         1  GR - GENERAL REGULATIONS GR.1 FORMULA SAE COMP...   \n",
       "1         2  GR.1.4.2 The vehicle should have high performa...   \n",
       "2         3  GR.2.4 Restriction on Vehicle Use SAE Internat...   \n",
       "3         4  GR.3.5.2 If a team is not present and ready to...   \n",
       "4         5  GR.4.4 Rules Compliance GR.4.4.1 All participa...   \n",
       "\n",
       "                                        rule_numbers  \\\n",
       "0  [\"EV.5.2\", \"GR.1.2.3\", \"GR.1.3\", \"GR.1.4\", \"GR...   \n",
       "1  [\"GR.1.4.2\", \"GR.1.4.3\", \"GR.1.4.4\", \"GR.1.5\",...   \n",
       "2  [\"GR.1.2.3\", \"GR.3.1\", \"GR.3.2\", \"GR.3.3\", \"GR...   \n",
       "3  [\"GR.3.5.2\", \"GR.3.5.3\", \"GR.4.1\", \"GR.4.2.1\",...   \n",
       "4  [\"GR.4.4\", \"GR.4.4.1\", \"GR.4.4.2\", \"GR.4.4.3\",...   \n",
       "\n",
       "                                            keywords  \\\n",
       "0  [\"Build\", \"Competition\", \"Demonstration\", \"Des...   \n",
       "1  [\"Dynamic events\", \"Static events\", \"aesthetic...   \n",
       "2  [\"Competition organizers\", \"Competition site\",...   \n",
       "3  [\"Competition\", \"Competition year\", \"Draft rul...   \n",
       "4  [\"FSAE Online Website\", \"Formula SAE Rules\", \"...   \n",
       "\n",
       "                                  cluster_group_list  \n",
       "0  [\"Cluster 447\", \"Cluster 214\", \"Cluster 12\", \"...  \n",
       "1  [\"Cluster 56\", \"Cluster 63\", \"Cluster 219\", \"C...  \n",
       "2  [\"Cluster 105\", \"Cluster 214\", \"Cluster 87\", \"...  \n",
       "3  [\"Cluster 214\", \"Cluster 65\", \"Cluster 87\", \"C...  \n",
       "4  [\"Cluster 231\", \"Cluster 87\", \"Cluster 48\", \"C...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('rules_chunks_with_clusters.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1481d6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['rule_numbers'] = df['rule_numbers'].apply(ast.literal_eval)\n",
    "df['cluster_group_list'] = df['cluster_group_list'].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2cd330c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load cluster text file into a dictionary\n",
    "def parse_clusters(filepath):\n",
    "    cluster_map = {}\n",
    "    with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            if \":\" in line:\n",
    "                cluster_id, keywords = line.strip().split(\":\", 1)\n",
    "                cluster_map[cluster_id.strip()] = keywords.strip()\n",
    "    return cluster_map\n",
    "\n",
    "cluster_dict = parse_clusters(\"keyword_clusters.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6cb20a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neo4j connection\n",
    "AUTH = (USER, PASSWORD)\n",
    "\n",
    "# Test connectivity\n",
    "with GraphDatabase.driver(URI, auth=AUTH) as driver:\n",
    "    driver.verify_connectivity()\n",
    "    print(\"âœ… Connected to Neo4j successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a2c4cb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph schema creation (with keyword embeddings)\n",
    "def create_text_rule_cluster_graph(tx, chunk_id, text, rules, cluster_id, cluster_keywords, cluster_embedding):\n",
    "    query = \"\"\"\n",
    "    MERGE (t:Text {chunk_id: $chunk_id})\n",
    "    SET t.content = $text\n",
    "    MERGE (c:Cluster {name: $cluster_id})\n",
    "    SET c.keywords_text = $cluster_keywords,\n",
    "        c.keywords_embedding = $cluster_embedding\n",
    "    MERGE (t)-[:HAS_KEYWORDS_IN]->(c)\n",
    "    WITH t\n",
    "    UNWIND $rules AS rule_number\n",
    "        MERGE (r:Rule {rule_number: rule_number})\n",
    "        MERGE (t)-[:CONTAINS_RULE]->(r)\n",
    "    \"\"\"\n",
    "    tx.run(\n",
    "        query,\n",
    "        chunk_id=chunk_id,\n",
    "        text=text,\n",
    "        rules=rules,\n",
    "        cluster_id=cluster_id,\n",
    "        cluster_keywords=cluster_keywords,\n",
    "        cluster_embedding=cluster_embedding\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a8d5e461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load embedding model (1024 dimension)\n",
    "embedding_model = SentenceTransformer(\"BAAI/bge-large-en-v1.5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "82dbf1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create embedding dictionary for all clusters\n",
    "cluster_embedding_dict = {}\n",
    "for cluster_id, keywords_text in cluster_dict.items():\n",
    "    emb = embedding_model.encode(keywords_text, normalize_embeddings=True)\n",
    "    cluster_embedding_dict[cluster_id] = emb.tolist()  # Neo4j stores as list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "282c3b88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Software\\Anaconda\\Temp\\ipykernel_16464\\3498529262.py:2: DeprecationWarning: Using a driver after it has been closed is deprecated. Future versions of the driver will raise an error.\n",
      "  with driver.session() as session:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Neo4j graph with Cluster nodes and relationships successfully created.\n"
     ]
    }
   ],
   "source": [
    "# graph creation\n",
    "with driver.session() as session:\n",
    "    for idx, row in df.iterrows():\n",
    "        chunk_id = row['chunk_id']\n",
    "        text = row['text']\n",
    "        rules = row['rule_numbers']\n",
    "        cluster_list = row['cluster_group_list']\n",
    "\n",
    "        for cluster_id in cluster_list:\n",
    "            cluster_keywords = cluster_dict.get(cluster_id, \"\")\n",
    "            cluster_embedding = cluster_embedding_dict.get(cluster_id, [])\n",
    "            session.execute_write(\n",
    "                create_text_rule_cluster_graph,\n",
    "                chunk_id,\n",
    "                text,\n",
    "                rules,\n",
    "                cluster_id,\n",
    "                cluster_keywords,\n",
    "                cluster_embedding\n",
    "            )\n",
    "\n",
    "print(\"âœ… Neo4j graph with Cluster nodes and relationships successfully created.\")\n",
    "#driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1635c3",
   "metadata": {},
   "source": [
    "## GraphRAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b38533b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neo4j Connected\n"
     ]
    }
   ],
   "source": [
    "# Test connection to neo4j database\n",
    "def test_connection(tx):\n",
    "  result = tx.run(\"RETURN 'Neo4j Connected' AS message\")\n",
    "  return result.single()[\"message\"]\n",
    "\n",
    "with driver.session() as session:\n",
    "  message = session.execute_read(test_connection)\n",
    "  print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841f436d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 11.45it/s]\n",
      "Some parameters are on the meta device because they were offloaded to the disk and cpu.\n",
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "# LLM integration\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "\n",
    "model_name = r\"C:\\Users\\pt8527\\OneDrive - The University of Texas at Austin\\Summer 2025\\IDETC-CIE 2025\\Hackathon2025\\models\\models--meta-llama--Llama-3.2-11B-Vision-Instruct\"  \n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, token=my_token, device_map=\"auto\", torch_dtype=\"auto\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, token=my_token)\n",
    "\n",
    "hf_pipeline = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235cc535",
   "metadata": {},
   "outputs": [],
   "source": [
    "# An adapter so neo4j-graphrag gets an object with `.content`\n",
    "class HFLLMAdapter:\n",
    "    def __init__(self, pipe, max_new_tokens=64):\n",
    "        self.pipe = pipe\n",
    "        self.max_new_tokens = max_new_tokens\n",
    "\n",
    "    def invoke(self, prompt: str):\n",
    "        out = self.pipe(\n",
    "            prompt,\n",
    "            max_new_tokens=self.max_new_tokens,\n",
    "            do_sample=False,           # deterministic\n",
    "            # when do_sample=False, temperature/top_p are ignored (so no warnings)\n",
    "            return_full_text=False\n",
    "        )\n",
    "        text = out[0][\"generated_text\"].strip()\n",
    "        # return an object with a `.content` attribute\n",
    "        return type(\"LLMResult\", (object,), {\"content\": text})()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461bdbcc",
   "metadata": {},
   "source": [
    "Rule extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c85162",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Software\\Anaconda\\Temp\\ipykernel_16464\\1577644718.py:18: DeprecationWarning: Using a driver after it has been closed is deprecated. Future versions of the driver will raise an error.\n",
      "  with driver.session() as session:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved: rule_retrieval_qa_2_with_predictions_2.csv\n"
     ]
    }
   ],
   "source": [
    "# allow multiple chunk search\n",
    "in_path = \"rule_retrieval_qa_2.csv\"\n",
    "out_path = \"rule_retrieval_qa_2_with_predictions_2.csv\"\n",
    "\n",
    "# load CSV\n",
    "df_ext = pd.read_csv(in_path)\n",
    "\n",
    "# batch query function\n",
    "def batch_chunk_ids(tx, rule_numbers):\n",
    "    query = \"\"\"\n",
    "    UNWIND $rules AS rn\n",
    "    MATCH (r:Rule {rule_number: rn})<-[:CONTAINS_RULE]-(t:Text)\n",
    "    WITH rn, collect(DISTINCT t.chunk_id) AS chunk_ids\n",
    "    RETURN rn AS rule_number, chunk_ids\n",
    "    \"\"\"\n",
    "    return {rec[\"rule_number\"]: rec[\"chunk_ids\"] for rec in tx.run(query, rules=rule_numbers)}\n",
    "\n",
    "# run batch lookup\n",
    "with driver.session() as session:\n",
    "    # keep original order from CSV\n",
    "    rule_list = df[\"rule_number\"].tolist()\n",
    "    # get mapping: rule_number -> [chunk_ids...]\n",
    "    rn_to_chunks = session.execute_read(batch_chunk_ids, rule_list)\n",
    "\n",
    "# fill model_prediction column (comma-joined)\n",
    "def join_chunks(rn):\n",
    "    chunks = rn_to_chunks.get(rn, [])\n",
    "    # join to a single string; empty list -> empty string\n",
    "    return \",\".join(map(str, chunks)) if chunks else \"\"\n",
    "\n",
    "df_ext[\"model_prediction\"] = df_ext[\"rule_number\"].apply(join_chunks)\n",
    "\n",
    "# --- save updated CSV ---\n",
    "df_ext.to_csv(out_path, index=False)\n",
    "print(f\"âœ… Saved: {out_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61d3e5f",
   "metadata": {},
   "source": [
    "Rule compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4288d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieval_query_comp = \"\"\"\n",
    "    WHERE node:Cluster\n",
    "    MATCH (node)<-[:HAS_KEYWORDS_IN]-(t:Text)-[:CONTAINS_RULE]->(r:Rule)\n",
    "    RETURN DISTINCT r.rule_number AS result, score\n",
    "    \"\"\"\n",
    "\n",
    "cluster_vector_retriever = VectorCypherRetriever(\n",
    "    driver=driver,\n",
    "    index_name=\"cluster_keywords_vector_index\",\n",
    "    retrieval_query=retrieval_query_comp\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2cbc76d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Rule Number: GR.3.5.2\n",
      "   Score: 0.8079407215118408\n",
      "----------------------------------------\n",
      "2. Rule Number: GR.3.5.3\n",
      "   Score: 0.8079407215118408\n",
      "----------------------------------------\n",
      "3. Rule Number: GR.4.1\n",
      "   Score: 0.8079407215118408\n",
      "----------------------------------------\n",
      "4. Rule Number: GR.4.2.1\n",
      "   Score: 0.8079407215118408\n",
      "----------------------------------------\n",
      "5. Rule Number: GR.4.2.2\n",
      "   Score: 0.8079407215118408\n",
      "----------------------------------------\n",
      "6. Rule Number: GR.4.2.3\n",
      "   Score: 0.8079407215118408\n",
      "----------------------------------------\n",
      "7. Rule Number: GR.4.2.4\n",
      "   Score: 0.8079407215118408\n",
      "----------------------------------------\n",
      "8. Rule Number: GR.4.3.1\n",
      "   Score: 0.8079407215118408\n",
      "----------------------------------------\n",
      "9. Rule Number: GR.4.3.2\n",
      "   Score: 0.8079407215118408\n",
      "----------------------------------------\n",
      "10. Rule Number: GR.4.3.3\n",
      "   Score: 0.8079407215118408\n",
      "----------------------------------------\n",
      "11. Rule Number: T.6.2.2\n",
      "   Score: 0.8079407215118408\n",
      "----------------------------------------\n",
      "12. Rule Number: T.7\n",
      "   Score: 0.8079407215118408\n",
      "----------------------------------------\n",
      "13. Rule Number: T.7.1\n",
      "   Score: 0.8079407215118408\n",
      "----------------------------------------\n",
      "14. Rule Number: T.7.1.1\n",
      "   Score: 0.8079407215118408\n",
      "----------------------------------------\n",
      "15. Rule Number: T.7.1.2\n",
      "   Score: 0.8079407215118408\n",
      "----------------------------------------\n",
      "16. Rule Number: T.7.1.3\n",
      "   Score: 0.8079407215118408\n",
      "----------------------------------------\n",
      "17. Rule Number: T.7.1.4\n",
      "   Score: 0.8079407215118408\n",
      "----------------------------------------\n",
      "18. Rule Number: T.7.1.5\n",
      "   Score: 0.8079407215118408\n",
      "----------------------------------------\n",
      "19. Rule Number: T.7.2\n",
      "   Score: 0.8079407215118408\n",
      "----------------------------------------\n",
      "20. Rule Number: T.7.2.1\n",
      "   Score: 0.8079407215118408\n",
      "----------------------------------------\n",
      "21. Rule Number: T.7.2.2\n",
      "   Score: 0.8079407215118408\n",
      "----------------------------------------\n",
      "22. Rule Number: T.7.2.3\n",
      "   Score: 0.8079407215118408\n",
      "----------------------------------------\n",
      "23. Rule Number: T.7.2.4\n",
      "   Score: 0.8079407215118408\n",
      "----------------------------------------\n",
      "24. Rule Number: AD.1\n",
      "   Score: 0.797266960144043\n",
      "----------------------------------------\n",
      "25. Rule Number: AD.1.1\n",
      "   Score: 0.797266960144043\n",
      "----------------------------------------\n",
      "26. Rule Number: AD.1.2\n",
      "   Score: 0.797266960144043\n",
      "----------------------------------------\n",
      "27. Rule Number: AD.1.3\n",
      "   Score: 0.797266960144043\n",
      "----------------------------------------\n",
      "28. Rule Number: AD.2\n",
      "   Score: 0.797266960144043\n",
      "----------------------------------------\n",
      "29. Rule Number: AD.2.1\n",
      "   Score: 0.797266960144043\n",
      "----------------------------------------\n",
      "30. Rule Number: AD.2.2\n",
      "   Score: 0.797266960144043\n",
      "----------------------------------------\n",
      "31. Rule Number: AD.2.2.1\n",
      "   Score: 0.797266960144043\n",
      "----------------------------------------\n",
      "32. Rule Number: AD.2.2.2\n",
      "   Score: 0.797266960144043\n",
      "----------------------------------------\n",
      "33. Rule Number: AD.2.2.3\n",
      "   Score: 0.797266960144043\n",
      "----------------------------------------\n",
      "34. Rule Number: GR.9.3.2\n",
      "   Score: 0.797266960144043\n",
      "----------------------------------------\n",
      "35. Rule Number: GR.9.3.3\n",
      "   Score: 0.797266960144043\n",
      "----------------------------------------\n",
      "36. Rule Number: GR.1.2.3\n",
      "   Score: 0.797266960144043\n",
      "----------------------------------------\n",
      "37. Rule Number: T.4.2.3\n",
      "   Score: 0.797266960144043\n",
      "----------------------------------------\n",
      "38. Rule Number: T.4.2.4\n",
      "   Score: 0.797266960144043\n",
      "----------------------------------------\n",
      "39. Rule Number: T.4.2.5\n",
      "   Score: 0.797266960144043\n",
      "----------------------------------------\n",
      "40. Rule Number: T.4.2.6\n",
      "   Score: 0.797266960144043\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Test manual retrieval\n",
    "query_text = (\n",
    "    \"Please list all rules relevant to `Firewall`. \"\n",
    "    \"Answer with only the rule numbers (i.e.: AA.1.1.1) separated by commas and no other words. \"\n",
    "    \"The rules relevant to `Firewall` are:\"\n",
    ")\n",
    "embedding_vector = embedding_model.encode(query_text, normalize_embeddings=True).tolist()\n",
    "print(embedding_vector)\n",
    "\n",
    "# Manually call retriever.get_search_results\n",
    "retriever_result = cluster_vector_retriever.get_search_results(\n",
    "    query_vector=embedding_vector,  # Needed but not directly used\n",
    "    query_text=None,  # Needed for formatting\n",
    "    top_k=2,\n",
    "    query_params={\"topK\": 2, \"embedding\": embedding_vector}\n",
    ")\n",
    "\n",
    "# Print the results nicely\n",
    "for idx, item in enumerate(retriever_result.records, start=1):\n",
    "    print(f\"{idx}. Rule Number: {item.get('result', 'N/A')}\")\n",
    "    print(f\"   Score: {item.get('score', 'N/A')}\")\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5dbbb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Syntax: return CHUNK IDs tied to the matched cluster/text\n",
    "retrieval_query_chunks = \"\"\"\n",
    "    WHERE node:Cluster\n",
    "    MATCH (node)<-[:HAS_KEYWORDS_IN]-(t:Text)\n",
    "    RETURN DISTINCT coalesce(t.chunk_id, id(t)) AS chunk_id,\n",
    "                    t.content AS text,\n",
    "                    score\n",
    "    ORDER BY score DESC\n",
    "\"\"\"\n",
    "cluster_vector_retriever = VectorCypherRetriever(\n",
    "    driver=driver,\n",
    "    index_name=\"cluster_keywords_vector_index\",\n",
    "    retrieval_query=retrieval_query_chunks\n",
    ")\n",
    "\n",
    "def phrases_to_text(phrases):\n",
    "    if phrases is None:\n",
    "        return \"\"\n",
    "    if isinstance(phrases, list):\n",
    "        vals = [str(p).strip() for p in phrases if str(p).strip()]\n",
    "        return \" ; \".join(vals) if vals else \"\"\n",
    "    if isinstance(phrases, str):\n",
    "        s = phrases.strip()\n",
    "        if s.startswith('[') and s.endswith(']'):\n",
    "            try:\n",
    "                parsed = ast.literal_eval(s)\n",
    "                if isinstance(parsed, list):\n",
    "                    return phrases_to_text(parsed)\n",
    "            except Exception:\n",
    "                pass\n",
    "        return s\n",
    "    return str(phrases)\n",
    "\n",
    "def find_chunk_ids(keyword_phrases_all, top_k_clusters=10):\n",
    "    qtext = phrases_to_text(keyword_phrases_all).strip()\n",
    "    if not qtext:\n",
    "        return \"\"\n",
    "    qvec = embedding_model.encode(qtext, normalize_embeddings=True).tolist()\n",
    "    res = cluster_vector_retriever.get_search_results(\n",
    "        query_vector=qvec,\n",
    "        top_k=top_k_clusters,\n",
    "        query_params={\"topK\": top_k_clusters, \"embedding\": qvec}\n",
    "    )\n",
    "    # Collect chunk IDs, dedupe while preserving order\n",
    "    seen = set()\n",
    "    ordered_chunks = []\n",
    "    for rec in res.records:\n",
    "        cid = rec.get(\"chunk_id\")\n",
    "        if cid is None:\n",
    "            continue\n",
    "        # normalize to string for consistent CSV like \"20,21,32\"\n",
    "        cid_str = str(cid)\n",
    "        if cid_str not in seen:\n",
    "            seen.add(cid_str)\n",
    "            ordered_chunks.append(cid_str)\n",
    "    return \", \".join(ordered_chunks)\n",
    "\n",
    "# Batch\n",
    "df_comp = pd.read_csv(r\"rule_compilation_qa_2.csv\")\n",
    "df_comp[\"chunk_id_list\"] = df_comp[\"keyword_phrases_all\"].apply(find_chunk_ids)\n",
    "\n",
    "df_comp.to_csv(r\"rule_compilation_qa_2_with_predictions_3.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "print(\"âœ… Saved: rule_compilation_qa_2_with_predictions_3.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
